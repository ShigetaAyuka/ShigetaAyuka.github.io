<html lang="ja">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta http-equiv="Content-Style-Type" content="text/css">
<meta http-equiv="Content-Script-Type" content="text/javascript">
<title>Spoken Dialog by Javascript</title>
</head>
<body>

<h1>課題：音声対話</h1>

<p>
<button id="startButton">start</button>
<button id="stopButton">stop</button>
</p>

<p>
<div id="resultOutput"></div>
</p>

<script>

// 応答の定義（ハッシュ）    
var response = {
    "誰":["わたしはプログラムです","undefined"],
    "歳":["私は0歳です","undefined"],
    "元気":["私に調子は関係ありません","undefined"],
    "食べ物":["何も食べません","undefined"],
    
    // 追加された文字列の組み合わせで回答が変わる
    "今日,天気":["今日は雨です","undefined"],
    "明日,天気":["明日は晴れです","undefined"],
    "今日,天気,晴":["違います。今日は雨です。","undefined"],
    "今日,天気,雨":["そうです","undefined"],
    "明日,天気,晴":["そうです","undefined"],
    "明日,天気,雨":["違います。明日は晴れです。","undefined"],
    
    //リンクを表示する
    "和歌山,天気": ["和歌山県の天気予報を表示します", "https://weather.yahoo.co.jp/weather/jp/30/"],
    "大阪,天気": ["大阪府の天気予報を表示します", "https://weather.yahoo.co.jp/weather/jp/27/"],
    "京都,天気": ["京都府の天気予報を表示します", "https://weather.yahoo.co.jp/weather/jp/26/"],
    "奈良,天気": ["奈良県の天気予報を表示します", "https://weather.yahoo.co.jp/weather/jp/29/"],
    "兵庫,天気": ["兵庫県の天気予報を表示します", "https://weather.yahoo.co.jp/weather/jp/28/"],
    
    // 過去にさかのぼった結果によって回答が変わる
    "興味":["そんなに私のことが知りたいのですか","undefined"]
};

// ウエイクワードの定義
var wake_word = "OK.*コンピューター";


//追加課題実行用メソッド（その回の認識結果と過去の結果の入った配列を引数に取る）
function keyword(newText, textArray, transcript) {
  let lastText = '';
  let webpage;
  let key;
  let ret;

  // 過去にさかのぼる際に必要な文字列だけの配列
  let specialWords = ["誰", "歳", "食べ物"];
  // 過去にさかのぼる際に必要なカウンター
  let count = 0;
  
  // 文字列を全て確認
  keys = Object.keys(response);
  keys.forEach(function(key) {
    let flag = true;
    key.split(',').forEach(function(word) {
      let pattern = new RegExp(word);
      let flag_test = pattern.test(transcript);
      flag = flag && flag_test;
    });
    if(flag){
      ret = response[key];
      lastText = ret[0];
      webpage = ret[1];
      console.log(key + " : " + lastText);
    }
  });
  
  textArray.push(newText);
  // 直近3つのデータを見るために抽出
  let recentTexts = textArray.slice(-3);
  
  // 直近３回分を特定の3つの単語が入っているかどうか調べて、カウンターを変更する
  for (let j = 0; j < recentTexts.length; j++) {
    for (let k = 0; k < specialWords.length; k++) {
      if (recentTexts[j].indexOf(specialWords[k]) !== -1) {
        count++;
      }
    }
  }

  // カウンターが３以上、つまり直近3回とも、特定の種類のこと（プログラム個人に対する質問）だとするとlastTextを「興味」に変更
  if (count >= 3) {
    key = '興味';
    ret = response[key];
    lastText = ret[0];
    webpage = ret[1];
    console.log(key + " : " + lastText);
    
  }
  
  // lastTextが空の時はそのまま元の文字列を返し、何か入っていればlastTextを返す
  if (lastText === '') {
    return ["ごめんなさい。わかりません。","undefined"];
  }
  else {
    return [lastText,webpage];
    
  }
}

const startButton = document.querySelector('#startButton'); // 開始ボタン
const stopButton = document.querySelector('#stopButton'); // 停止ボタン
const resultOutput = document.querySelector('#resultOutput'); // 結果出力エリア

if (!'SpeechSynthesisUtterance' in window) {
    alert("あなたのブラウザはSpeech Synthesis APIに未対応です。");
}
const tts = new SpeechSynthesisUtterance(); // TTSインスタンスを生成
//tts.text = textForm.value; // テキストを設定
tts.lang = "ja-JP"; // 言語(日本語)、英語の場合はen-US
tts.rate = 1.0; // 速度
tts.pitch = 1.0; // 声の高さ
tts.volume = 1.0; // 音量

SpeechRecognition = webkitSpeechRecognition || SpeechRecognition;
if (!'SpeechRecognition' in window) {
    alert("あなたのブラウザはSpeech Recognition APIに未対応です。");
}

const asr = new SpeechRecognition(); // ASRインスタンスを生成
asr.lang = "ja-JP"; // 言語（日本語）
asr.interimResults = true; // 途中結果出力をオン
asr.continuous = true; // 継続入力をオン

let output = ''; // 出力
let textArray = []; // 過去の認識結果を記録する配列
let listeningForCommand = false; // ウエイクワード後の音声認識フラグ

// 認識結果が出力されたときのイベントハンドラ
asr.onresult = function(event){
    let transcript = event.results[event.resultIndex][0].transcript; // 結果文字列
    let transcript_previous = null; 
    
    if(event.resultIndex > 0){
        transcript_previous = event.results[event.resultIndex - 1][0].transcript;
    }
    
    let newText = '';
    let resultText = '';
    let text = '';
    let webpage;

    let output_not_final = '';
        
    if (event.results[event.resultIndex].isFinal) { // 結果が確定（Final）のとき
	    if(new RegExp(wake_word).test(transcript_previous)){
            asr.abort(); // 音声認識を停止
            listeningForCommand = true; // コマンド入力を待つ状態にする
      }
        
      if (listeningForCommand) {
            
        newText = transcript.replace(/\r?\n/g,'').replace(/\0/g,''); // 余計な文字の削除
    
        // 追加課題用のメソッドを使用
        [text, webpage] = keyword(newText, textArray, transcript);

        tts.text = text;
        // 再生が終了（end）ときのイベントハンドラ（終了したときに実行される）
        tts.onend = function(event){
          if(webpage != 'undefined'){
              location.href = webpage; // ページを移動
          }
          asr.start(); // 音声認識を再開
        }

        speechSynthesis.speak(tts); // 再生
        resultText = transcript + " => " + text + '<br>';
      }
    } else { // 結果がまだ未確定のとき
        output_not_final = '<span style="color:#ddd;">' + transcript + '</span>';
    }
    resultOutput.innerHTML = output + resultText + output_not_final; // 応答結果の出力
    output += resultText;
}

// 開始ボタンのイベントハンドラ
startButton.addEventListener('click', function() {
    asr.start();
})

// 停止ボタンのイベントハンドラ
stopButton.addEventListener('click', function() {
    asr.stop();
    listeningForCommand = false;
})

</script>

</body>
</html>
